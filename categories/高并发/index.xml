<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>高并发 on 淡淡忧愁</title>
    <link>https://timx.cn/categories/%E9%AB%98%E5%B9%B6%E5%8F%91/</link>
    <description>Recent content in 高并发 on 淡淡忧愁</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Aug 2018 11:08:10 +0800</lastBuildDate>
    
	<atom:link href="https://timx.cn/categories/%E9%AB%98%E5%B9%B6%E5%8F%91/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>web高并发的理解和发现</title>
      <link>https://timx.cn/post/complicated/</link>
      <pubDate>Wed, 22 Aug 2018 11:08:10 +0800</pubDate>
      
      <guid>https://timx.cn/post/complicated/</guid>
      <description>高并发的理解 发现问题  这几天登录服务器上线，发现注册新用户数据库有多条记录！！
 跟踪分析问题   查询nginx的访问日志发现有相同的请求同时请求。 查看代码逻辑发现创建新用户时，先查询mysql是否有相同的用户udid。如果有，那么直接返回用户主键id。没有就插入一条数据。 逻辑非常简单，也没有用上缓存。   本地重现   ab创建注册接口。10个用户并发，100个人次。 ab发现数据库出现了重复数据。概率90%以上。   上网查询解决方案 redis缓存   用户访问注册接口。 先访问缓存如果有用户id就直接返回用户id 没有就插入redis缓存一条，然后再访问数据库查询是否存在，不存在就插入mysql，再更新缓存。    本地测试ab创建注册接口。10个用户并发，100个人次。没有发现重复数据
直到ab 60个用户并发，200人次再次出现重复数据，复现80%左右。
没有完美解决
 还是redis缓存  直接用redis做防护层，控制相同udid一秒内只能一次，其他返回失败。 本地测试ab创建注册接口。10个用户并发，100个人次。没有发现重复数据
直到ab 60个用户并发，200人次再次出现重复数据，复现80%左右。 没有完美解决
 使用文件锁或者redis锁  这个没有实现测试，思考时，我不打算用代码层做阻塞用户的操作！！！
 使用队列  让注册用户的并发串行化。使用延迟插入。可以解决。
队列带来异步的问题。需要客户端配合。
 mysql的唯一索引  这个可以解决但是会有报错返回对客户端不友好，不合适。
 使用mysql InnoDB的悲观锁  查询时候进行行锁，然后再插入。最后提交。
ab创建注册接口。10个用户并发，100个人次。没有发现重复数据
直到ab 60个用户并发，200人次没有出现重复数据。
本地完美解决。
 网上解决方案思考。 利用redis做缓存还是不能完美解决并发的问题，只能解决一部分。如果使用redis集群提高处理速度和延迟，买更好的机器。可以降低并发出问题的几率，但不完美，不可扩展。 利用mysql悲观锁可以解决但是会让mysql性能下降，并且代码逻辑不严谨有产生死锁的可能。所以mysql的悲观锁也不是一个好的解决方案。
询问其他人 游戏服务器他们的处理是用单进程单线程来解决。</description>
    </item>
    
  </channel>
</rss>